# svm-kernel-tutorial-report
This project takes a closer look at different SVM kernels like Linear, Polynomial, and RBF by using visualizations and running experiments on synthetic datasets. It comes with a Jupyter notebook and a concise report that illustrates how the choice of kernel and hyperparameters can influence decision boundaries.
# Files Included

- likith_ML.ipynb — This file contains the complete implementation, along with visualizations and experiments.

- Final_SVM_Report.pdf — A concise summary of the methods used, results obtained, and key observations made.

- README.md — An overview of the project and a guide on how to use it.

# What the Project Demonstrates

- Linear kernel: works well for straightforward, linearly separable data.

- Polynomial kernel: adds nonlinear curves depending on the degree.

- RBF kernel: ideal for capturing complex patterns; it’s sensitive to the parameters C and gamma.

- Visual comparisons illustrate the effects of underfitting and overfitting.

# Requirements

To get started, create a Python 3.8+ environment and install the following packages:

- numpy
- scipy
- scikit-learn
- matplotlib
- pandas
- seaborn
- notebook
- jupyterlab (if needed)

# How to Run

1. Run `pip install -r requirements.txt`
2. Launch the notebook with `jupyter notebook likith_ML.ipynb`

# Purpose

The goal is to offer a clear, visual insight into how choosing different kernels affects SVM classification, helping students and beginners develop a better understanding of model behavior.

# Author

Likith Rathipinni
